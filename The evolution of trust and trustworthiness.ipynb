{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The evolution of trust and trustworthiness\n",
    "## By Alex MARCELINO SANTEE, Jean-Nicolas GREGOIRE, Sacha TESTAERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "# import egttools as egt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# from egttools.games import Matrix2PlayerGameHolder\n",
    "# from scipy.integrate import odeint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "##### Single game (Trust game, binary decision)\n",
    "##### Strategies are a combination of A,B (T,R), (T,B), (N,R), (N,B)\n",
    "\n",
    "##### Game matrix:\n",
    "|     |  R                 |  B                |\n",
    "|-----|------------------------|-------------------|\n",
    "|  T  |  1 + (3r - 1)x, 3(1 - r)x  |  1 - x, 3x  |\n",
    "|  N  |  1, 0              |  1, 0        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"black\", \"green\", \"red\", \"blue\"]\n",
    "strategy_labels = [\"(T,R)\", \"(T,B)\", \"(N,R)\", \"(N,B)\"]\n",
    "\n",
    "nb_strategies = 4\n",
    "nb_runs = 5 #128\n",
    "nb_time_steps = 10\n",
    "n_threads = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trust Game Simulation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act2int(action: str):\n",
    "    if action == \"T\" or action == \"R\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def gen_trust_matrix(x=1, r=0.5):\n",
    "    # Trust Game Matrix\n",
    "    #   R B\n",
    "    # T\n",
    "    # N\n",
    "    matrix = np.array([\n",
    "        [[1-x+3*r*x, 3*x*(1-r)], [1-x, 3*x]],\n",
    "        [[1, 0], [1, 0]],\n",
    "    ])\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def gen_strategies_matrix(x=1, r=0.5):\n",
    "    # Strategies are (T,R), (T,B), (N,R), (N,B)\n",
    "    # A\\B  (TR) (TB) (NR) (NB)\n",
    "    # (TR)\n",
    "    # (TB)\n",
    "    # (NR)\n",
    "    # (NB)\n",
    "    # Averaging the results for main diagonal (or we cant use egttools)\n",
    "    base = gen_trust_matrix(x, r)\n",
    "    matrix = np.empty((4, 4))\n",
    "    # using bit 1 is T/N, bit 0 is R/B\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            if i < j:  # over main diagonal is A reward\n",
    "                matrix[i, j] = base[i // 2, j % 2, 0]\n",
    "            elif i > j:  # below main diagonal is B reward\n",
    "                matrix[i, j] = base[i // 2, j % 2, 1]\n",
    "            else:  # i==j\n",
    "                matrix[i, j] = np.sum(base[i // 2, j % 2])/2\n",
    "    return matrix\n",
    "\n",
    "# Multiple network types - pair are generated from connected nodes\n",
    "# well-mixed, lattice (triangle, square, hexagon), random and scale-free\n",
    "# heterogeneous networks can consider different degree (normalized) or not\n",
    "# unnormalized scale-free network is the only to evolve trust\n",
    "\n",
    "\n",
    "class AgentNetwork(ABC):\n",
    "    @abstractmethod\n",
    "    def sample_neighbors(self, agent, n=4, replacement=True):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_strategy(self, agent):\n",
    "        return self.strategies[agent]\n",
    "\n",
    "    def set_strategy(self, agent, strategy):\n",
    "        if strategy in strategy_labels:\n",
    "            self.strategies[agent] = strategy\n",
    "            return\n",
    "        else:\n",
    "            raise ValueError(\"Setting invalid strategy: \" + str(strategy))\n",
    "\n",
    "    def get_ratios(self):\n",
    "        count = Counter(self.strategies)\n",
    "        ratios = np.empty(nb_strategies)\n",
    "        for i, strategy in enumerate(strategy_labels):\n",
    "            ratios[i] = count[strategy]\n",
    "        return ratios/self.size\n",
    "\n",
    "    def get_size(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.strategies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well mixed network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WellMixed(AgentNetwork):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.strategies = random.choices(strategy_labels, k=size)\n",
    "        self.cs = 1024  # cache size\n",
    "        self.sample_cache = []  # improves sampling performance\n",
    "        for _ in range(self.size):\n",
    "            self.sample_cache.append([self.cs, np.empty((self.cs, 4))])\n",
    "\n",
    "\n",
    "    def sample_neighbors(self, agent, n=4, replacement=True):\n",
    "        if replacement:\n",
    "            if self.sample_cache[agent][0] >= self.cs:\n",
    "                neighbors = [x for x in range(self.size) if x != agent]\n",
    "                self.sample_cache[agent][1] = np.random.choice(neighbors,\n",
    "                                                               (self.cs, n))\n",
    "                self.sample_cache[agent][0] = 0\n",
    "            agents = self.sample_cache[agent][1][self.sample_cache[agent][0]]\n",
    "            self.sample_cache[agent][0] += 1\n",
    "        else:\n",
    "            neighbors = [x for x in range(self.size) if x != agent]\n",
    "            agents = random.sample(neighbors, n)\n",
    "        return agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Square lattice network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquareLattice(AgentNetwork):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.rows = math.ceil(self.size**(1/2))\n",
    "        self.cols = math.ceil(self.size**(1/2))\n",
    "        self.network = self._create_square_lattice(self.rows, self.cols)\n",
    "        self.strategies = random.choices(strategy_labels, k=self.size)\n",
    "\n",
    "    def _create_square_lattice(self, rows, cols):\n",
    "        G = nx.grid_2d_graph(rows, cols, periodic=True) #must remain to True, otherwise the network is padded\n",
    "        mapping = {node: idx for idx, node in enumerate(G.nodes)}\n",
    "        # Relabel nodes in the graph using the mapping \n",
    "        # (G is first created with tuples representing nodes id and coordinates \n",
    "        # but since we want to sample over them, it's easier with one dimensional identificator)\n",
    "        G = nx.relabel_nodes(G, mapping)\n",
    "        print(G)\n",
    "        return G    \n",
    "    \n",
    "    def sample_neighbors(self, agent, n=4, replacement=True):\n",
    "        neighbors = list(self.network.neighbors(agent))\n",
    "        if replacement or len(neighbors) < n:\n",
    "            agents = np.random.choice(neighbors, n)\n",
    "        else:\n",
    "            agents = random.sample(neighbors, n)\n",
    "        return agents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triangle lattice network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TriangleLattice(AgentNetwork):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.rows = math.ceil(self.size**(1/2))\n",
    "        self.cols = math.ceil(self.size**(1/2))\n",
    "        self.network = self._create_triangular_lattice(self.rows, self.cols)\n",
    "        self.strategies = random.choices(strategy_labels, k=self.size)\n",
    "\n",
    "    def _create_triangular_lattice(self, rows, cols):\n",
    "        G = nx.triangular_lattice_graph(rows, cols, periodic=True) \n",
    "        mapping = {node: idx for idx, node in enumerate(G.nodes)}\n",
    "        G = nx.relabel_nodes(G, mapping)\n",
    "        return G\n",
    "    \n",
    "    def sample_neighbors(self, agent, n=4, replacement=True):\n",
    "        neighbors = list(self.network.neighbors(agent))\n",
    "        if replacement or len(neighbors) < n:\n",
    "            agents = np.random.choice(neighbors, n)\n",
    "        else:\n",
    "            agents = random.sample(neighbors, n)\n",
    "        return agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hexagonal lattice network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HexagonLattice(AgentNetwork):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.rows = math.ceil(self.size**(1/2))\n",
    "        self.cols = math.ceil(self.size**(1/2))\n",
    "        self.network = self._create_hexagonal_lattice(self.rows, self.cols)\n",
    "        self.strategies = random.choices(strategy_labels, k=self.size)\n",
    "\n",
    "    def _create_hexagonal_lattice(self, rows, cols):\n",
    "        G = nx.hexagonal_lattice_graph(rows, cols, periodic=True)\n",
    "        mapping = {node: idx for idx, node in enumerate(G.nodes)}\n",
    "        G = nx.relabel_nodes(G, mapping)\n",
    "        return G\n",
    "    \n",
    "    def sample_neighbors(self, agent, n=4, replacement=True):\n",
    "        neighbors = list(self.network.neighbors(agent))\n",
    "        if replacement or len(neighbors) < n:\n",
    "            agents = np.random.choice(neighbors, n)\n",
    "        else:\n",
    "            agents = random.sample(neighbors, n)\n",
    "        return agents\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation\n",
    "\n",
    "###### Copy of other players actions with probability from eq. 2.1\n",
    "###### 1 / ( 1 + e^(tot_payoff_p2-tot_payoff_p1)/K ) for K=0.1\n",
    "###### number of MC steps equals to population size N=500\n",
    "###### Initializes each player randomly consists in chosing two players P1, P2 and playing the game w/ 4 neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.92 1.68]\n",
      "  [0.2  2.4 ]]\n",
      "\n",
      " [[1.   0.  ]\n",
      "  [1.   0.  ]]]\n"
     ]
    }
   ],
   "source": [
    "x, r = (0.8, 0.3)\n",
    "game_matrix = gen_strategies_matrix(x, r)\n",
    "game_matrix = gen_trust_matrix(x, r)\n",
    "print(game_matrix)\n",
    "# game = Matrix2PlayerGameHolder(4, game_matrix)\n",
    "\n",
    "t = np.arange(0, nb_time_steps)\n",
    "\n",
    "\n",
    "def simulation_step(\n",
    "        network: AgentNetwork,\n",
    "        payoff_matrix: np.ndarray,\n",
    "        ):\n",
    "    N_PLAYERS = 2\n",
    "    N_GAMES = 4\n",
    "    K = 0.1\n",
    "\n",
    "    # sample 2 players\n",
    "    players = random.sample(range(network.get_size()), N_PLAYERS)\n",
    "    payoffs = N_PLAYERS*[0]\n",
    "    for play_idx, player in enumerate(players):\n",
    "        # plays 4 games for each player\n",
    "        adversaries = network.sample_neighbors(player, n=N_GAMES)\n",
    "        for adversary in adversaries:\n",
    "\n",
    "            # decide roles\n",
    "            role = random.randint(0, 1)  # 0 player sends, 1 player receive\n",
    "            # gets actions\n",
    "            if role == 0:\n",
    "                act0 = network.get_strategy(player)[1]\n",
    "                act1 = network.get_strategy(adversary)[3]\n",
    "            else:\n",
    "                act0 = network.get_strategy(adversary)[1]\n",
    "                act1 = network.get_strategy(player)[3]\n",
    "            # calculates payoff for the game\n",
    "            payoff = payoff_matrix[act2int(act0), act2int(act1), role]\n",
    "\n",
    "            payoffs[play_idx] += payoff\n",
    "\n",
    "        # p2 copies p1 with chance w\n",
    "        w = 1 / (1 + np.exp(payoffs[1]-payoffs[0])/K)\n",
    "        if random.random() < w:\n",
    "            network.set_strategy(players[1],\n",
    "                                 network.get_strategy(players[0]))\n",
    "\n",
    "    return network\n",
    "\n",
    "\n",
    "def simulation_single_run(payoff_matrix: np.ndarray, population_type: str=\"SquareLattice\", pop_size=529):\n",
    "    results = np.empty((nb_time_steps, nb_strategies))\n",
    "\n",
    "    if population_type == \"SquareLattice\":\n",
    "            network = SquareLattice(pop_size)\n",
    "    elif population_type == \"TriangleLattice\":\n",
    "            network = TriangleLattice(pop_size)\n",
    "    elif population_type == \"HexagonLattice\":\n",
    "            network = HexagonLattice(pop_size)\n",
    "    elif population_type == \"WellMixed\":\n",
    "        network = WellMixed(pop_size)\n",
    "\n",
    "    for timestep in range(nb_time_steps):\n",
    "        for _ in range(pop_size):  # Each MC step is the size of population\n",
    "            network = simulation_step(network, payoff_matrix)\n",
    "        results[timestep] = network.get_ratios()\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_simulation(payoff_matrix: np.ndarray):\n",
    "    results = np.empty((nb_runs, nb_time_steps, nb_strategies))\n",
    "    with Pool(processes=n_threads) as p:\n",
    "        it = p.imap_unordered(simulation_single_run, nb_runs*[payoff_matrix])\n",
    "        for run, result in enumerate(it):\n",
    "            results[run] = result\n",
    "    return results\n",
    "\n",
    "\n",
    "results = run_simulation(game_matrix)\n",
    "results = np.asarray(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "\n",
    "#### 1- Proportion of population sweeping through x and r\n",
    "#### 2- Evolution Through time given x and r\n",
    "\n",
    "---\n",
    "\n",
    "###### Research question - what if keep memory of neighbor, can we train for (x,r)? What are ultimatum game and dictator game?\n",
    "###### To trust or not to trust proposes a better N-player generalization with code and found incentives to trustees and non-linear reward create rich evolution hierarchical trust fixes proportion of trusters and trustees and introduces punishing truster, getting stability of trustworthy and punishers.\n",
    "\n",
    "###### N-player trust game proposes variation with governors and citizens which players can select what to be (doesn't look interesting) converge to no trust unless population is full of trustworthy. To trust or not to trust cites it directly, but with strong criticism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for population evolution\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "\n",
    "for run in results:\n",
    "    for i in range(nb_strategies):\n",
    "        ax.plot(t, run[:, i],\n",
    "                linewidth=.05, alpha=0.6, color=colors[i])\n",
    "\n",
    "for i in range(nb_strategies):\n",
    "    ax.plot(t, np.mean(results[:, :, i], axis=0), linewidth=1.5,\n",
    "            alpha=1, color=colors[i], label=strategy_labels[i])\n",
    "\n",
    "ax.set_title(f\"evolution for $x$={x} and $r$={r}\")\n",
    "ax.legend(frameon=False, bbox_to_anchor=(1.1, 1, 0, 0), loc='upper right')\n",
    "ax.set_ylabel(\"frequency\", fontsize=14)\n",
    "ax.set_xlabel(\"time step, $t$\", fontsize=14)\n",
    "# ax.set_ylim(-0.2, 1.2)\n",
    "sns.despine()\n",
    "plt.show()\n",
    "\n",
    "# Sweep plot\n",
    "\n",
    "xs = np.linspace(0, 1, 20)\n",
    "rs = np.linspace(0, 1, 20)\n",
    "t = np.arange(0, 10, 10/nb_time_steps)\n",
    "\n",
    "\n",
    "def plot_heatmaps(avg_results):\n",
    "    fig, axs = plt.subplots(figsize=(10, 5), ncols=2, nrows=2)\n",
    "\n",
    "    im = axs[0, 0].imshow(avg_results[:, :, 0], cmap=\"inferno\", vmin=0.0, vmax=1.0,\n",
    "                     origin=\"lower\", extent=[0, 1, 0, 1], aspect=0.5,)\n",
    "    axs[0, 1].imshow(avg_results[:, :, 1], cmap=\"inferno\", vmin=0.0, vmax=1.0,\n",
    "                     origin=\"lower\", extent=[0, 1, 0, 1], aspect=0.5,)\n",
    "    axs[1, 0].imshow(avg_results[:, :, 2], cmap=\"inferno\", vmin=0.0, vmax=1.0,\n",
    "                     origin=\"lower\", extent=[0, 1, 0, 1], aspect=0.5,)\n",
    "    axs[1, 1].imshow(avg_results[:, :, 3], cmap=\"inferno\", vmin=0.0, vmax=1.0,\n",
    "                     origin=\"lower\", extent=[0, 1, 0, 1], aspect=0.5,)\n",
    "\n",
    "    axs[0, 0].text(0.8, 0.8, \"(T,R)\", backgroundcolor=\"white\")\n",
    "    axs[0, 1].text(0.8, 0.8, \"(T,B)\", backgroundcolor=\"white\")\n",
    "    axs[1, 0].text(0.8, 0.8, \"(N,R)\", backgroundcolor=\"white\")\n",
    "    axs[1, 1].text(0.8, 0.8, \"(N,B)\", backgroundcolor=\"white\")\n",
    "\n",
    "    axs[0, 0].set_xticks([])\n",
    "    axs[0, 1].set_xticks([])\n",
    "    axs[0, 1].set_yticks([])\n",
    "    axs[1, 1].set_yticks([])\n",
    "\n",
    "    axs[0, 0].set_ylabel(\"$r$\", fontsize=14)\n",
    "    axs[1, 0].set_ylabel(\"$r$\", fontsize=14)\n",
    "    axs[1, 0].set_xlabel(\"$x$\", fontsize=14)\n",
    "    axs[1, 1].set_xlabel(\"$x$\", fontsize=14)\n",
    "\n",
    "    fig.colorbar(im, ax=axs[:, :])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "final_proportions = np.empty((xs.shape[0], rs.shape[0], nb_strategies))\n",
    "for i, x in enumerate(xs):\n",
    "    for j, r in enumerate(rs):\n",
    "        payoff = gen_trust_matrix(x, r)\n",
    "        result = np.array(run_simulation(payoff))\n",
    "        final_proportions[i, j] = np.sum(result[:, -1, :], axis=0)/nb_runs\n",
    "    print(\"x =\", x)\n",
    "plot_heatmaps(final_proportions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egtenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
